# PySpark ETL Data Marts on PostgreSQL

ğŸš€ **End-to-End PySpark ETL pipeline** for building analytical **Data Marts** on **PostgreSQL**, following modern **Data Engineering** and **Dimensional Modeling (Star Schema)** principles.

This project demonstrates how to:
- Process data using **PySpark**
- Apply structured **ETL pipelines**
- Load curated data into **PostgreSQL**
- Build **Data Marts** optimized for analytics
- Design **Star Schema** for reporting and BI tools


---

## ğŸ§  Architecture Overview

The project follows a layered ETL approach inspired by modern data architectures:

Source Data (MSSQL)
â†“
PySpark ETL
â†“
PostgreSQL (Silver / Gold Layer)
â†“
Data Marts (Star Schema)

![Pyspark  Diagram](Pyspark_Diagram.png)


ğŸ“Œ Focus is on **clean separation of concerns**:
- ETL logic
- Configuration management
- Database procedures
- Analytical data modeling

---

## ğŸ“Š Data Modeling

The analytical layer is modeled using a **Star Schema**, optimized for BI and reporting.

### â­ Silver Layer â€“ Star Schema
![Silver Layer Star Schema](Silver_Layer_Star_schema.png)

**Components:**
- Fact tables for measurable business events
- Dimension tables for descriptive attributes
- Foreign key relationships for analytical joins

---

## ğŸ—‚ Project Structure

Pyspark_ETL_dataMartsON_PostgreSQL/
â”‚
â”œâ”€â”€ etl/
â”‚ â”œâ”€â”€ main.py # Entry point for ETL pipeline
â”‚ â”œâ”€â”€ Pipline.py # Core ETL orchestration logic
â”‚ â””â”€â”€ init.py
â”‚
â”œâ”€â”€ Utils/
â”‚ â”œâ”€â”€ config.py # Environment & configuration handling
â”‚ â”œâ”€â”€ postgres_procedures.py # PostgreSQL procedure execution
â”‚ â””â”€â”€ init.py
â”‚
â”œâ”€â”€ diagrams/
â”‚ â””â”€â”€ Silver_Layer_Star_schema.png
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â””â”€â”€ README.md






---

## âš™ï¸ Technologies Used

- **Python 3**
- **PySpark**
- **PostgreSQL**
- **psycopg2**
- **python-dotenv**
- **Linux / Ubuntu**
- **Dimensional Modeling (Star Schema)**

---

## ğŸ” Configuration

Environment variables are managed using `.env` file.

Create a `.env` file based on the example:

```env
PG_HOST=localhost
PG_PORT=5432
PG_DATABASE=datamart
PG_USER=postgres
PG_PASSWORD=your_password
